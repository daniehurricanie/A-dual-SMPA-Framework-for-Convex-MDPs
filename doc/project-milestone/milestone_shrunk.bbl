\begin{thebibliography}{3}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Asad et~al.(2024)Asad, Harikandeh, Laradji, Roux, and Vaswani]{asad2024fast}
R.~Asad, R.~B. Harikandeh, I.~H. Laradji, N.~L. Roux, and S.~Vaswani.
\newblock Fast convergence of softmax policy mirror ascent for bandits \& tabular {MDP}s.
\newblock 2024.
\newblock URL \url{https://openreview.net/forum?id=f5OjNMXIik}.

\bibitem[Ding et~al.(2020)Ding, Zhang, Ba{\c{s}}ar, and Jovanovi{\'c}]{ding2020npgpd}
D.~Ding, K.~Zhang, T.~Ba{\c{s}}ar, and M.~R. Jovanovi{\'c}.
\newblock Natural policy gradient primal-dual method for constrained markov decision processes.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2020.

\bibitem[Zahavy et~al.(2021)Zahavy, O'Donoghue, Desjardins, and Singh]{zahavy2021reward}
T.~Zahavy, B.~O'Donoghue, G.~Desjardins, and S.~Singh.
\newblock Reward is enough for convex mdps.
\newblock volume~34, pages 25746--25759, 2021.

\end{thebibliography}
